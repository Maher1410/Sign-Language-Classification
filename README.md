# Sign-Language-Classification


This repository contains a comprehensive end-to-end pipeline for the classification of American Sign Language (ASL) hand gestures using Convolutional Neural Networks (CNNs). The project commences by accessing the ASL dataset stored in Google Drive, followed by preprocessing steps which include image resizing and normalization. We then define, compile, and train a CNN model using TensorFlow and Keras. The model's performance is diligently evaluated through accuracy, loss plots, a detailed classification report, and a confusion matrix. Additionally, the model is saved for future deployment and inference purposes. As a feature highlight, we've integrated an interactive GUI using Gradio, allowing users to upload an image and instantly receive a classification prediction. This not only provides a hands-on way to test the model but also makes the project more accessible to non-technical users. The entire codebase is structured neatly, ensuring ease of understanding and adaptability for similar tasks.

